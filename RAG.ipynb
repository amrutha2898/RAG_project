{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e952d989-309f-4262-9d69-e11eac4a27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data set\n",
      "\n",
      "Epoch: 1, Batch: 1\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 2\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 3\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 4\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 5\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 6\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 7\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 1, Batch: 8\n",
      "Precision: 0, Recall: 0, F1 Score: 0\n",
      "Epoch: 2, Batch: 1\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 2\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 3\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 4\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 5\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 6\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 7\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 2, Batch: 8\n",
      "Precision: 0, Recall: 0, F1 Score: 0\n",
      "Epoch: 3, Batch: 1\n",
      "Precision: 1.0, Recall: 0.5, F1 Score: 0.6666666666666666\n",
      "Epoch: 3, Batch: 2\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 3, Batch: 3\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 3, Batch: 4\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 3, Batch: 5\n",
      "Precision: 0, Recall: 0, F1 Score: 0\n",
      "Epoch: 3, Batch: 6\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 3, Batch: 7\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 3, Batch: 8\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 4, Batch: 1\n",
      "Precision: 0, Recall: 0.0, F1 Score: 0\n",
      "Epoch: 4, Batch: 2\n",
      "Precision: 1.0, Recall: 0.5, F1 Score: 0.6666666666666666\n",
      "Epoch: 4, Batch: 3\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 4, Batch: 4\n",
      "Precision: 1.0, Recall: 0.5, F1 Score: 0.6666666666666666\n",
      "Epoch: 4, Batch: 5\n",
      "Precision: 1.0, Recall: 0.6666666666666666, F1 Score: 0.8\n",
      "Epoch: 4, Batch: 6\n",
      "Precision: 0, Recall: 0, F1 Score: 0\n",
      "Epoch: 4, Batch: 7\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 4, Batch: 8\n",
      "Precision: 1.0, Recall: 0.6666666666666666, F1 Score: 0.8\n",
      "Epoch: 5, Batch: 1\n",
      "Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Epoch: 5, Batch: 2\n",
      "Precision: 1.0, Recall: 0.3333333333333333, F1 Score: 0.5\n",
      "Epoch: 5, Batch: 3\n",
      "Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Epoch: 5, Batch: 4\n",
      "Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Epoch: 5, Batch: 5\n",
      "Precision: 1.0, Recall: 0.6666666666666666, F1 Score: 0.8\n",
      "Epoch: 5, Batch: 6\n",
      "Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Epoch: 5, Batch: 7\n",
      "Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
      "Epoch: 5, Batch: 8\n",
      "Precision: 0, Recall: 0, F1 Score: 0\n",
      "\n",
      "Predicted Citations : \n",
      "Revenue Ruling 2022-10, 2022-1 I.R.B. 123 (2022) (Ruling on tax treatment of cryptocurrency transactions).\n",
      "Revenue Procedure 2022-5, 2022-1 I.R.B. 234 (2022) (Procedure for requesting tax refund).\n",
      "Treasury Regulation ยง 1.368-1 (Regulation on corporate reorganizations).\n",
      "Revenue Ruling 74-162, 1974-1 C.B. 250 (1974) (Ruling on tax treatment of religious proselytizing literature).\n",
      "Church of Hope v. Internal Revenue Service (D.C. Md. 2023).(Case on religuous activities)\n",
      "\n",
      "Actual Citations : \n",
      "Revenue Ruling 2022-10, 2022-1 I.R.B. 123 (2022) (Ruling on tax treatment of cryptocurrency transactions).\n",
      "Johnson v. Smith, 567 F.3d 890 (8th Cir. 2009) (Case on tax implications of stock options).\n",
      "Revenue Procedure 2022-5, 2022-1 I.R.B. 234 (2022) (Procedure for requesting tax refund).\n",
      "Treasury Regulation ยง 1.368-1 (Regulation on corporate reorganizations).\n",
      "Revenue Ruling 74-162, 1974-1 C.B. 250 (1974) (Ruling on tax treatment of religious proselytizing literature).\n",
      "Church of Hope v. Internal Revenue Service (D.C. Md. 2023).(Case on religuous activities)\n",
      "\n",
      "For test data set\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.8333333333333334\n",
      "F1 Score: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "# Load the pre-trained SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add new entity labels for legal codes, case names, and court jurisdictions\n",
    "ner = nlp.get_pipe('ner')\n",
    "ner.add_label('LAW')\n",
    "ner.add_label('CASE')\n",
    "ner.add_label('COURT')\n",
    "\n",
    "\n",
    "keywords = [\n",
    "    \"religious\", \n",
    "    \"tax-exempt\", \n",
    "    \"IRS\", \n",
    "    \"commercial activity\", \n",
    "    \"Code\", \n",
    "    \"Regulation\", \n",
    "    \"Statute\", \n",
    "    \"Provision\", \n",
    "    \"Section\", \n",
    "    \"Subsection\", \n",
    "    \"Title\", \n",
    "    \"Clause\", \n",
    "    \"Article\", \n",
    "    \"Amendment\",\n",
    "    \"Church\",\n",
    "    \"Religion\",\n",
    "    \"Faith\",\n",
    "    \"Worship\",\n",
    "    \"Congregation\",\n",
    "    \"Minister\",\n",
    "    \"Pastor\",\n",
    "    \"Synagogue\",\n",
    "    \"Mosque\",\n",
    "    \"Temple\",\n",
    "    \"Deduction\",\n",
    "    \"Exemption\",\n",
    "    \"Revenue\",\n",
    "    \"Income\",\n",
    "    \"Taxpayer\",\n",
    "    \"Taxable\",\n",
    "    \"Tax-exempt\",\n",
    "    \"Taxation\",\n",
    "    \"IRS Code\",\n",
    "    \"Tax shelter\"\n",
    "]\n",
    "\n",
    "\n",
    "fuzzy_threshold = 80  \n",
    "\n",
    "def is_near_keyword(sentence):\n",
    "    for keyword in keywords:\n",
    "        if fuzz.partial_ratio(keyword, sentence) >= fuzzy_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def calculate_f1_score(correct_citations, predicted_citations):\n",
    "    tp = fp = fn = 0\n",
    "    total_positive = sum(correct_citations)\n",
    "\n",
    "    for i in range(len(correct_citations)):\n",
    "        if correct_citations[i] == 1 and predicted_citations[i] == 1:\n",
    "            tp += 1\n",
    "        elif correct_citations[i] == 0 and predicted_citations[i] == 1:\n",
    "            fp += 1\n",
    "        elif correct_citations[i] == 1 and predicted_citations[i] == 0:\n",
    "            fn += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "def calculate_f1_score_text(correct_citations, predicted_citations):\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for correct_sent in correct_citations:\n",
    "        if correct_sent in predicted_citations:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    for predicted_sent in predicted_citations:\n",
    "        if predicted_sent not in correct_citations:\n",
    "            fp += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "\n",
    "def find_citations(text):\n",
    "    citations = []\n",
    "    \n",
    "    with open(\"testcase.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading and trailing whitespace, including the newline character\n",
    "            if line:  # Skip empty lines\n",
    "                sentences.append(line)\n",
    " \n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "       \n",
    "        pattern = r\"\\bv\\.\"\n",
    "        match = re.search(pattern,sentence)\n",
    "        entities = [ent.label_ for ent in doc.ents]\n",
    "\n",
    "        if is_near_keyword(sentence):\n",
    "            if match:\n",
    "                if \"CASE\" in entities and \"CODE\" in entities:\n",
    "                    citations.append(sentence)\n",
    "\n",
    "            else:   \n",
    "                if \"LAW\" in entities and \"CODE\" in entities:\n",
    "                    citations.append(sentence)\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def is_citation(sentence):\n",
    "    citations = []\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "       \n",
    "    pattern = r\"\\bv\\.\"\n",
    "    match = re.search(pattern,sentence)\n",
    "    entities = [ent.label_ for ent in doc.ents]\n",
    "\n",
    "    if is_near_keyword(sentence):\n",
    "        if match:\n",
    "                if \"CASE\" in entities and \"CODE\" in entities:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "        else:   \n",
    "                if \"LAW\" in entities and \"CODE\" in entities:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "train_data = [\n",
    "\n",
    "    (\"IRC ยง 501 defines religious organizations.\", {\"entities\": [(0, 5, \"LAW\"),(6,9,\"CODE\")]},1),\n",
    "    (\"Bob Jones University v. Simon is a landmark case.\", {\"entities\": [(0, 29, \"CASE\")]},0),\n",
    "    (\"Mormon Church v. United States, 136 U.S. 1 (1890).(Case on religious organization funding)\",{\"entities\":[(0,31,\"CASE\"),(32,42,\"CODE\")]},1),\n",
    "    (\"RUNYON v. McCRARY, 427 U.S. 160 96 S. Ct. 258 (1976).\",{\"entities\": [(0, 18, \"CASE\"),(19,31,\"CODE\"),(32,45,\"COURT\")]},0),\n",
    "    (\"SMITH v. JONES, 427 U.S. 160 97 S. Ct. 259 (1977).\",{\"entities\": [(0, 14, \"CASE\"),(16,28,\"CODE\"),(29,42,\"COURT\")]},0),\n",
    "    (\"DOE v. ROE, 427 U.S. 160 98 S. Ct. 260 (1978).\",{\"entities\": [(0, 10, \"CASE\"),(12,24,\"CODE\"),(25,38,\"COURT\")]},0),\n",
    "    \n",
    "    (\"Hermitage Ministries Inc. v. Commissioner (73 T.C. 1106 (1979)) (Case on religious organizations and fundraising activities)\",{\"entities\":[(0,41,\"CASE\"),(43,55,\"COURT\")]},1),\n",
    "    (\"Texas Heart Hospital of St. Luke's Episcopal Health Charities, Inc. v. United States (978 F.2d 280 (5th Cir. 1992)) (Case on religious hospitals and tax exemption)\",{\"entities\":[(0,84,\"CASE\"),(86,98,\"CODE\"),(100,108,\"COURT\")]},1),\n",
    "    (\"Johnson v. Rogers, 120 F.3d 5 (1st Cir. 1997) (Case on tax exemption for religious institutions)\",{\"entities\":[(0,17,\"CASE\"),(19,29,\"CODE\"),(31,39,\"COURT\")]},1),\n",
    "    (\"Evans v. United States, 23 F.3d 304 (4th Cir. 1994) (Case on IRS regulations)\",{\"entities\":[(0,22,\"CASE\"),(24,35,\"CODE\"),(37,45,\"COURT\")]},1),\n",
    "    (\"Smith v. Commissioner, 15 T.C. 1 (1950) (Case on tax deductions for charitable contributions)\",{\"entities\":[(0,21,\"CASE\"),(23,32,\"CODE\")]},1),\n",
    "    (\"IRS Revenue Ruling 70-549, 1970-2 C.B. 103 (1970) (Ruling on tax-exempt status of religious organizations)\",{\"entities\":[(0,3,\"LAW\"),(4,11,\"LAW\"),(34,42,\"CODE\")]},1),\n",
    "    (\"IRC ยง 501(c)(3) (Provision for tax exemption of religious, charitable, and certain other organizations)\",{\"entities\":[(0,5,\"LAW\"),(6,15,\"CODE\")]},1),\n",
    "    (\"Fraternal Order of Eagles v. United States, 15 F.3d 1097 (9th Cir. 1994) (Case on tax-exempt status of fraternal organizations)\",{\"entities\":[(0,42,\"CASE\"),(44,56,\"CODE\"),(58,66,\"COURT\")]},1),\n",
    "    (\"John Doe v. Commissioner, 123 T.C. 456 (2004) (Case on anonymity of donors to religious organizations)\",{\"entities\":[(0,24,\"CASE\"),(26,38,\"CODE\")]},1),\n",
    "    (\"St. Paul's Lutheran Church v. Commissioner, 82 T.C. 371 (1984) (Case on tax treatment of church property)\",{\"entities\":[(0,42,\"CASE\"),(44,55,\"CODE\")]},1),\n",
    "    (\"IRC ยง 513 (Definition of unrelated business taxable income for tax-exempt organizations)\",{\"entities\":[(0,5,\"LAW\"),(6,9,\"CODE\")]},1),\n",
    "    (\"Treasury Regulation ยง 1.501(c)(3)-1 (Regulation defining requirements for tax-exempt status under IRC ยง 501(c)(3))\",{\"entities\":[(0,21,\"LAW\"),(22,35,\"CODE\")]},1),\n",
    "    (\"Citizens for the Abatement of Aircraft Noise, Inc. v. County of Orange, 126 F.3d 1294 (9th Cir. 1997) (Case on tax exemption for noise abatement organizations)\",{\"entities\":[(0,70,\"CASE\"),(72,85,\"CODE\"),(87,95,\"COURT\")]},1),\n",
    "    (\"IRC ยง 508 (Provision for exemption from filing annual information returns for certain organizations)\",{\"entities\":[(0,5,\"LAW\"),(6,9,\"CODE\")]},1),\n",
    "    (\"IRS Revenue Procedure 2018-5, 2018-1 I.R.B. 233 (2018) (Procedure for applying for reinstatement of tax-exempt status)\",{\"entities\":[(0,3,\"LAW\"),(4,11,\"LAW\"),(37,47,\"CODE\")]},1),\n",
    "    (\"Revenue Ruling 74-162, 1974-1 C.B. 250 (1974) (Ruling on tax treatment of religious proselytizing literature)\",{\"entities\":[(0,7,\"LAW\"),(30,38,\"CODE\")]},1),\n",
    "    (\"Church of Hope v. Internal Revenue Service (D.C. Md. 2023).\",{\"entities\":[(0,42,\"CASE\"),(44,52,\"CODE\")]},1)\n",
    "    # Add more annotated examples based on the provided citations\n",
    "]\n",
    "\n",
    "\n",
    "# Split the training data into batches of 3\n",
    "# Split the training data into batches of 3\n",
    "batch_size = 3\n",
    "batches = [train_data[i:i+batch_size] for i in range(0, len(train_data), batch_size)]\n",
    "\n",
    "print(\"For training data set\")\n",
    "print()\n",
    "# Iterate over each batch and train the model\n",
    "epoch_num = 5\n",
    "for epoch in range(epoch_num):  # Number of epochs\n",
    "    random.shuffle(batches)\n",
    "    for batch_num, batch in enumerate(batches, 1):\n",
    "        sentences = [item[0] for item in batch]\n",
    "        annotations = [item[1] for item in batch]\n",
    "        is_citation_labels = [item[2] for item in batch]\n",
    "\n",
    "        # Predict is_citation for each sentence\n",
    "        predicted_is_citation = [is_citation(sent) for sent in sentences]\n",
    "\n",
    "        # Calculate F1 score\n",
    "        precision, recall, f1 = calculate_f1_score(is_citation_labels, predicted_is_citation)\n",
    "\n",
    "        # Print epoch and batch numbers before printing precision, recall, and F1-score\n",
    "        print(f\"Epoch: {epoch + 1}, Batch: {batch_num}\")\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "        # Update the model for each example in the batch\n",
    "        for text, annotation in zip(sentences, annotations):\n",
    "            example = Example.from_dict(nlp.make_doc(text), annotation)\n",
    "            nlp.update([example])\n",
    "\n",
    "# Save the fine-tuned model\n",
    "nlp.to_disk('fine_tuned_model')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentences = []\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = 'testcase.txt'  # Update with your file path\n",
    "text = read_file(file_path)\n",
    "\n",
    "# Find citations in the text\n",
    "citations = find_citations(text)\n",
    "\n",
    "# Print the identified citations\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Predicted Citations : \")\n",
    "for citation in citations:\n",
    "    print(citation)\n",
    "\n",
    "\n",
    "file_path1 = \"corr_output.txt\"\n",
    "\n",
    "# Read the file and extract correct citations\n",
    "correct_citations = []\n",
    "with open(file_path1, \"r\") as file:\n",
    "    correct_citations = [line.strip() for line in file]\n",
    "\n",
    "\n",
    "print()\n",
    "# Assuming correct_citations and predicted_citations are lists of citations\n",
    "print(\"Actual Citations : \")\n",
    "for cit in correct_citations:\n",
    " print(cit)\n",
    "\n",
    "\n",
    "\n",
    "precision, recall, f1_score = calculate_f1_score_text(correct_citations, citations)\n",
    "\n",
    "print()\n",
    "print(\"For test data set\")\n",
    "print()\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb92d9d-2315-4078-9819-5d424c951256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
